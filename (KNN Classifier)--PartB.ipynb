{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (KNN Classifier)--PartB\n",
    "## Breast cancer wisconsin dataset\n",
    "In this assignment, we will build a KNN classifier that takes an features as as input and outputs a label 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer dataset contains 569 samples with 30 real, positive features (including cancer mass attributes like mean radius, mean texture, mean perimeter, et cetera). Of the samples, 212 are labeled “malignant” and 357 are labeled “benign”. \n",
    "You can find more details in: https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "## Load the training set\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  569\n",
      "Number of features per sample:  30\n",
      "Total number of classes:  [0 1]\n",
      "Number of malignant:  212\n",
      "Number of benign:  357\n"
     ]
    }
   ],
   "source": [
    "## print some statistics on the dataset\n",
    "### TODO YOUR CODE ###\n",
    "\n",
    "# print(\"Total number of samples: \", )\n",
    "print (\"Total number of samples: \", len(X))\n",
    "\n",
    "# print the number of features per sample\n",
    "print('Number of features per sample: ', X.shape[1])\n",
    "\n",
    "# Total number of classes\n",
    "print(\"Total number of classes: \", np.unique(y))\n",
    "\n",
    "# print the number of samples in each class\n",
    "print(\"Number of malignant: \", len(X) - np.count_nonzero(y))\n",
    "print(\"Number of benign: \", np.count_nonzero(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train data to Train and Validate Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "### TODO YOUR CODE ###\n",
    "\n",
    "# Split the data (i.e. features and target) into 70% train, 15% validate, and 15% test; Use Random Seed 777\n",
    "np.random.seed(777)\n",
    "trainx, X_rem, trainy, y_rem = train_test_split(X,y, train_size=0.7)\n",
    "valx, testx, valy, testy = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classification with L2 distance\n",
    "\n",
    "To compute nearest neighbors in our data set, we need to first be able to compute distances between data points. A natural distance function is _Euclidean distance_: for two vectors $x, y \\in \\mathbb{R}^d$, their Euclidean distance is defined as \n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "Often we omit the square root, and simply compute _squared Euclidean distance_:\n",
    "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
    "For the purposes of nearest neighbor computations, the two are equivalent: for three vectors $x, y, z \\in \\mathbb{R}^d$, we have $\\|x - y\\| \\leq \\|x - z\\|$ if and only if $\\|x - y\\|^2 \\leq \\|x - z\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **NN_L2**, which takes as input the training data (`trainx` and `trainy`) and the test points (`evalx`) and predicts labels for these test points using 1-NN classification. These labels should be returned in a `numpy` array with one entry per test point. For **NN_L2**, the L2 norm should be used as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L2(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    predicty = np.zeros(evalx.shape[0])\n",
    "    for i in range(evalx.shape[0]):\n",
    "        distance = []\n",
    "        for j in range(trainx.shape[0]):\n",
    "            euclidean_distance = np.linalg.norm(trainx[j] - evalx[i])\n",
    "            distance.append([euclidean_distance, trainy[j]])\n",
    "        predicty[i] = sorted(distance)[0][1]\n",
    "    \n",
    "    \n",
    "    return predicty\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L2**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L2(trainx, trainy, evalx, K):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "        \n",
    "    predicty = np.zeros(evalx.shape[0])\n",
    "    for i in range(evalx.shape[0]):\n",
    "        distance = []\n",
    "        for j in range(trainx.shape[0]):\n",
    "            euclidean_distance = np.linalg.norm(trainx[j] - evalx[i])\n",
    "            distance.append([euclidean_distance, trainy[j]])\n",
    "        sorted_distance = sorted(distance)\n",
    "        predicted_class = 0;\n",
    "        for val in range(K):\n",
    "            if sorted_distance[val][1] == 1:\n",
    "                predicted_class += 1\n",
    "            else:\n",
    "                predicted_class -= 1\n",
    "        \n",
    "        predicty[i] = 0.0\n",
    "        if predicted_class >= 0:\n",
    "            predicty[i] = 1.0\n",
    "            \n",
    "    \n",
    "    return predicty\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_L2(trainx, trainy, testx, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "Write a function, **NN_L1**, which again takes as input the arrays `trainx`, `trainy`, and `evalx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels should be returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_L1(trainx, trainy, evalx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    predicty = np.zeros(evalx.shape[0])\n",
    "    for i in range(evalx.shape[0]):\n",
    "        distance = []\n",
    "        for j in range(trainx.shape[0]):\n",
    "            euclidean_distance = np.linalg.norm(trainx[j] - evalx[i], 1)\n",
    "            distance.append([euclidean_distance, trainy[j]])\n",
    "        predicty[i] = sorted(distance)[0][1]\n",
    "    \n",
    "    \n",
    "    return predicty\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN_L1**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), and the value of **K** (integer) and predicts labels for these test points using K-NN classification and L1 distance metric. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_L1(trainx, trainy, evalx, K):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "        \n",
    "    predicty = np.zeros(evalx.shape[0])\n",
    "    for i in range(evalx.shape[0]):\n",
    "        distance = []\n",
    "        for j in range(trainx.shape[0]):\n",
    "            euclidean_distance = np.linalg.norm(trainx[j] - evalx[i], 1)\n",
    "            distance.append([euclidean_distance, trainy[j]])\n",
    "        sorted_distance = sorted(distance)\n",
    "        predicted_class = 0;\n",
    "        for val in range(K):\n",
    "            if sorted_distance[val][1] == 1:\n",
    "                predicted_class += 1\n",
    "            else:\n",
    "                predicted_class -= 1\n",
    "        \n",
    "        predicty[i] = 0.0\n",
    "        if predicted_class >= 0:\n",
    "            predicty[i] = 1.0\n",
    "            \n",
    "    \n",
    "    return predicty\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **KNN**, which takes as input the training data (`trainx` and `trainy`), the test points (`evalx`), the value of **K** (integer), and a parameter for deciding the distance metric to be used (for example 1 for L1 and 2 for L2) and predicts labels for these test points using KNN classification. These labels should be returned in a `numpy` array with one entry per test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainx, trainy, evalx, K, dist_metric=2):\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "        \n",
    "    predicty = np.zeros(evalx.shape[0])\n",
    "    for i in range(evalx.shape[0]):\n",
    "        distance = []\n",
    "        for j in range(trainx.shape[0]):\n",
    "            euclidean_distance = np.linalg.norm(trainx[j] - evalx[i], dist_metric)\n",
    "            distance.append([euclidean_distance, trainy[j]])\n",
    "        sorted_distance = sorted(distance)\n",
    "        predicted_class = 0;\n",
    "        for val in range(K):\n",
    "            if sorted_distance[val][1] == 1:\n",
    "                predicted_class += 1\n",
    "            else:\n",
    "                predicted_class -= 1\n",
    "        \n",
    "        predicty[i] = 0.0\n",
    "        if predicted_class >= 0:\n",
    "            predicty[i] = 1.0\n",
    "            \n",
    "    \n",
    "    return predicty\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that allows you to select the hyper-parameters (distance measure and the value of K) by calling the KNN classifier with different values of K and either L1 or L2 distance measure. Make sure that you set the hyper-parameters using the validation set and not the test set. You need to systemtically try different values for K in conjunction with a distance measure and tabulate the results (you can do that be craeting a seperate cell and documenting in that cell) and note down the best hyper-parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import unravel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.        ]\n",
      " [ 1.          1.          0.91764706]\n",
      " [ 1.          2.          0.88235294]\n",
      " [ 2.          1.          0.89411765]\n",
      " [ 2.          2.          0.90588235]\n",
      " [ 3.          1.          0.90588235]\n",
      " [ 3.          2.          0.92941176]\n",
      " [ 4.          1.          0.89411765]\n",
      " [ 4.          2.          0.91764706]\n",
      " [ 5.          1.          0.90588235]\n",
      " [ 5.          2.          0.92941176]\n",
      " [ 6.          1.          0.90588235]\n",
      " [ 6.          2.          0.92941176]\n",
      " [ 7.          1.          0.92941176]\n",
      " [ 7.          2.          0.92941176]\n",
      " [ 8.          1.          0.92941176]\n",
      " [ 8.          2.          0.91764706]\n",
      " [ 9.          1.          0.92941176]\n",
      " [ 9.          2.          0.91764706]\n",
      " [10.          1.          0.90588235]\n",
      " [10.          2.          0.91764706]\n",
      " [11.          1.          0.90588235]\n",
      " [11.          2.          0.91764706]\n",
      " [12.          1.          0.90588235]\n",
      " [12.          2.          0.90588235]\n",
      " [13.          1.          0.91764706]\n",
      " [13.          2.          0.90588235]\n",
      " [14.          1.          0.90588235]\n",
      " [14.          2.          0.90588235]\n",
      " [15.          1.          0.91764706]\n",
      " [15.          2.          0.91764706]\n",
      " [16.          1.          0.89411765]\n",
      " [16.          2.          0.90588235]\n",
      " [17.          1.          0.89411765]\n",
      " [17.          2.          0.90588235]\n",
      " [18.          1.          0.89411765]\n",
      " [18.          2.          0.88235294]\n",
      " [19.          1.          0.90588235]\n",
      " [19.          2.          0.88235294]\n",
      " [20.          1.          0.89411765]\n",
      " [20.          2.          0.88235294]\n",
      " [21.          1.          0.90588235]\n",
      " [21.          2.          0.88235294]\n",
      " [22.          1.          0.89411765]\n",
      " [22.          2.          0.88235294]\n",
      " [23.          1.          0.89411765]\n",
      " [23.          2.          0.89411765]\n",
      " [24.          1.          0.89411765]\n",
      " [24.          2.          0.88235294]]\n",
      "highest score is  0.9294117647058824 at k= 3.0 and L= 2.0\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "def val_accuracy(K, L, valx, valy):\n",
    "    predicty = KNN(trainx, trainy, valx, K, dist_metric=L)\n",
    "    \n",
    "#     print('accuracy score for knn with K =', K,' and L',L,' is: ', accuracy_score(valy, predicty))\n",
    "    return accuracy_score(valy, predicty)\n",
    "\n",
    "scores = np.array([[0,0,0]])\n",
    "for i in range(1,25):\n",
    "    for j in range (1,3):\n",
    "        x = val_accuracy(i, j, valx, valy)\n",
    "        scores = np.append(scores, [[i, j, x]],axis=0)\n",
    "         \n",
    "\n",
    "\n",
    "print (scores)\n",
    "max_index = scores.argmax(axis=0)\n",
    "print('highest score is ', scores[max_index[2]][2], 'at k=', scores[max_index[2]][0], 'and L=', scores[max_index[2]][1])\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the hyper-parameters have been selected, we now would like to perform a final evaluation on the test set and record the error rates. Also, Write a function, **confusion**, which takes as input the true labels for the test set (that is, `testy`) as well as the predicted labels and returns the confusion matrix. The confusion matrix should be a `np.array` of shape `(2,2)`. Also, record the confusion matrix in your assignment report.\n",
    "\n",
    "**Note:** Record the cpu time it takes to perform the evaluation on the test set using functions like **time.time()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(testy, testy_fit):\n",
    "    # inputs: the correct labels, the fitted KNN labels \n",
    "    # output: a 2x2 np.array representing the confusion matrix as above\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    \n",
    "    df_confusion = pd.crosstab(testy, testy_fit, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    return df_confusion\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.20447945594787598 seconds ---\n",
      "Accuracy = 0.9418604651162791\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>23</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  All\n",
       "Actual                  \n",
       "0           22    4   26\n",
       "1            1   59   60\n",
       "All         23   63   86"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for performing the final evaluation on the test set and generating the confuson matrix.\n",
    "### START CODE HERE ###\n",
    "start_time = time.time()\n",
    "predicty = KNN(trainx, trainy, testx, 3, dist_metric=2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Accuracy =',val_accuracy(3, 2, testx, testy))\n",
    "confusion(testy,predicty)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preparing the assignment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to prepare the assignment report and submit your code and report to the Blackboard assignment. You need to record your answers for the following questions in the report:\n",
    "1. What is the error rate on the validation set for NN_L2?\n",
    "2. What is the best error rate on the validation set for KNN_L2?\n",
    "3. What is the error rate on the validation set for NN_L1?\n",
    "4. What is the best error rate on the validation set for KNN_L1?\n",
    "5. What is the error rate on the test set?\n",
    "7. Do you need to normalize data, in general, when using KNN?\n",
    "8. Do you need to normalize data when using KNN for the given problem? Explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The error rate on validation set for NN_L2 is  0.11764705882352944\n",
      "2. The best error rate on validation set for KNN_L2 is  0.07058823529411762\n",
      "3. The error rate on validation set for NN_L1 is  0.08235294117647063\n",
      "4. The best error rate on validation set for NN_L1 is  0.07058823529411762\n",
      "5. The error rate on test set is  0.05813953488372092\n"
     ]
    }
   ],
   "source": [
    "print('1. The error rate on validation set for NN_L2 is ', 1-val_accuracy(1, 2, valx, valy))\n",
    "print('2. The best error rate on validation set for KNN_L2 is ', 1-val_accuracy(3, 2, valx, valy))\n",
    "print('3. The error rate on validation set for NN_L1 is ', 1-val_accuracy(1, 1, valx, valy))\n",
    "print('4. The best error rate on validation set for NN_L1 is ', 1-val_accuracy(8, 1, valx, valy))\n",
    "print('5. The error rate on test set is ', 1-val_accuracy(3, 2, testx, testy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extra Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are invited to try some more ideas as extra work like:\n",
    "1. Implementing weighted KNN where the vote of a neighbour is scaled down based on its distance from the test point.\n",
    "2. Implement L_infinity distance measure and use it for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep in mind the following points:\n",
    "1. Use numpy arrays and numpy libraries for efficient computations. \n",
    "2. Vectorize the code wherever possible instead of using explicit loops. This will significantly speed-up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
